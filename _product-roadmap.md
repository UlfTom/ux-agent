# UX Agent - Product Roadmap & Technical Strategy

**Datum**: 11. November 2025  
**Status**: MVP Development  
**Ziel**: 100% zuverlÃ¤ssige Basic-Simulation auf otto.de

---

## ğŸ¯ Die Vision (Endgame)

### User Flow (Finale Version)

```
1. User Input
   â”œâ”€ URL: https://www.otto.de
   â””â”€ Task: "Finde eine Winter-Jacke fÃ¼r junge Frauen"

2. UX RESEARCHER (Modul 2)
   â”œâ”€ Erstellt professionelle UX-Aufgabe aus Raw Input
   â”œâ”€ IF MODERIERT: Erstellt Fragenkatalog
   â”‚  â””â”€ "Wie fÃ¼hlt sich das an?"
   â”‚  â””â”€ "Wie mÃ¼helos war dieser Schritt?"
   â”‚  â””â”€ "Was wÃ¼rdest du dahinter erwarten?"
   â””â”€ Output: Strukturierte Test-Instruktion

3. GOTT (Modul 1) - Persona Factory
   â”œâ”€ Analysiert Task-Keywords ("Winter-Jacke", "junge Frauen")
   â”œâ”€ Generiert n=1 (spÃ¤ter n=100) passende Personas
   â”‚  â””â”€ NICHT: "Emily, 38, Buchhalterin"
   â”‚  â””â”€ SONDERN: "Lisa, 24, Studentin, Fashion-bewusst"
   â””â”€ Output: System-Prompt fÃ¼r Piloten

4. PILOT (Modul 3) - AusfÃ¼hrung
   â”œâ”€ Sieht Aufgabe: "Du suchst eine Winter-Jacke"
   â”œâ”€ FÃ¼hrt Test durch (MENSCHLICH simuliert)
   â”‚  â”œâ”€ Character-by-Character Typing: "w-i-n-t-e-r-j-a-c-k-e"
   â”‚  â”œâ”€ Enter-Key Detection (nicht nur Icon-Click)
   â”‚  â”œâ”€ Hover-Delays (100-300ms)
   â”‚  â””â”€ Screenshot-Dokumentation JEDER Aktion
   â””â”€ IF MODERIERT: Beantwortet Researcher-Fragen

5. RESEARCHER (Modul 2) - Auswertung
   â”œâ”€ IF BASIC: Nur Tabellen-Output (Steps, Actions, Time)
   â”œâ”€ IF PLUS: Detaillierte Zusammenfassung
   â”‚  â””â”€ "Es zeigte sich, dass 8 von 10 Personas..."
   â”‚  â””â”€ "Hauptproblem: Cookie-Banner blockiert Suche"
   â”‚  â””â”€ "Empfehlung: Banner verzÃ¶gert laden"
   â””â”€ Output: PDF Report + Visualisierung
```

---

## ğŸ”´ Aktuelle Probleme (Technical Debt)

### Problem 1: Schlechte Persona-Generierung

**Was passiert:**
```
Task: "Finde eine Winter-Jeans fÃ¼r Damen"
Persona: "Emily, 38, Buchhalterin, mag Fitness"
```

**Warum falsch:**
- Kein Bezug zur Aufgabe
- Generic Template-Text
- Mistral halluziniert Details

**LÃ¶sung:**
- Task-Keyword-Extraction: "Winter-Jeans" + "Damen" â†’ "Junge Frau, 25-35, Fashion-interessiert"
- Persona-Prompt muss Demographics + Motivation kombinieren
- Few-Shot Examples fÃ¼r Mistral

---

### Problem 2: Mistral bricht sofort ab

**Was passiert:**
```
Schritt 2/9: Llava sagt "Ich mÃ¶chte Winter-Jeans finden"
Mistral antwortet: { "action": "finish" }
```

**Warum falsch:**
- Mistral versteht nicht, dass "Absicht" â‰  "Schon erledigt"
- Keine klare Anweisung: "finish NUR wenn Produkt-Detail-Seite erreicht"

**LÃ¶sung:**
- Explizite Success-Criteria im Prompt
- Beispiel: "finish NUR wenn du ein PRODUKT siehst (mit Preis + In den Warenkorb)"
- Schleifenerkennung: 3x gleiche ID â†’ Researcher interveniert

---

### Problem 3: Keine Human-like Interaction

**Was passiert:**
```typescript
await locator.fill(aiAction.textToType); // Instant
```

**Warum falsch:**
- Echte Menschen tippen Buchstabe fÃ¼r Buchstabe
- Autocomplete-Dropdowns brauchen Zeit zum Erscheinen
- Keine Pausen zwischen Actions

**LÃ¶sung:**
```typescript
async function typeHumanLike(locator, text) {
  await locator.click(); // Focus first
  for (const char of text) {
    await locator.type(char, { delay: 50 + Math.random() * 100 }); // 50-150ms
  }
  await page.waitForTimeout(200); // Wait for autocomplete
}
```

---

### Problem 4: Enter-Key Support fehlt

**Was passiert:**
- Pilot kann nur auf Search-Icon klicken
- Echte User wÃ¼rden Enter drÃ¼cken

**LÃ¶sung:**
```typescript
if (aiAction.action === 'type' && aiAction.submitWithEnter) {
  await locator.fill(aiAction.textToType);
  await locator.press('Enter');
}
```

- Llava muss wissen: "Nach Tippen kannst du Enter drÃ¼cken ODER auf Icon [X] klicken"

---

### Problem 5: Schlechtes Logging

**Was passiert:**
```
ğŸ“Š Annotiere 433 Elemente
ğŸ‘ï¸ Llava analysiert...
ğŸ’­ Absicht: "Ich mÃ¶chte Winter-Jeans finden"
ğŸ§  Mistral entscheidet...
âœ… Aufgabe abgeschlossen
```

**Was fehlt:**
- Welche ID wurde gewÃ¤hlt?
- Welcher Text stand auf dem Element?
- Warum "finish"? (Rationale fehlt!)

**LÃ¶sung:**
```
Step 2/9 - Search Interaction
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ‘ï¸ Llava's Intention:
   "Ich sehe die Suchleiste [ID 1] und tippe 'Winter-Jeans'"

ğŸ§  Mistral's Decision:
   Action: type
   Target: ID 1 (role: textbox, text: "Wonach suchst du?")
   Text: "Winter-Jeans"
   Rationale: "Pragmatic persona uses search immediately"

âŒ¨ï¸ Execution:
   âœ“ Typed: w-i-n-t-e-r---j-e-a-n-s (1.2s)
   âœ“ Autocomplete appeared
   âœ“ Pressed Enter
   âœ“ Page navigated to /suche?q=winter-jeans

ğŸ“¸ Screenshot: [attached]
```

---

## ğŸ¯ MVP Roadmap - Phase 1 (NÃ¤chste 2 Wochen)

### Week 1: Core Fixes

**Day 1-2: Better Persona Generation**
- [ ] Task-Keyword-Extraction implementieren
- [ ] Demographics aus Keywords ableiten
- [ ] Few-Shot Examples fÃ¼r Mistral
- [ ] Test: "Winter-Jacke fÃ¼r junge Frauen" â†’ Lisa, 24

**Day 3-4: Human-like Typing**
- [ ] `typeHumanLike()` Funktion
- [ ] Character-by-character mit Random Delays
- [ ] Autocomplete Detection (waitForSelector)
- [ ] Enter-Key Support

**Day 5-7: Better Logging**
- [ ] Detailliertes Action-Log Format
- [ ] Rationale von Mistral anzeigen
- [ ] Execution-Details (Timing, Navigation)
- [ ] Error-Highlighting verbessern

---

### Week 2: Success Criteria & Stability

**Day 8-10: Finish-Logic Fix**
- [ ] Success Criteria explizit definieren
- [ ] "finish NUR wenn Produkt-Detail-Seite"
- [ ] Visual Cues fÃ¼r Mistral: "Siehst du Preis + Warenkorb?"
- [ ] Loop Detection (3x same ID â†’ Intervention)

**Day 11-12: Icon Understanding**
- [ ] Search Icon = Search (auch ohne Text)
- [ ] Burger Menu = Menu
- [ ] Common Icon Library fÃ¼r Llava
- [ ] Test: Kann Pilot Lupen-Icon erkennen?

**Day 13-14: End-to-End Test**
- [ ] 10x Test auf otto.de durchfÃ¼hren
- [ ] Success Rate: 8+/10 = MVP Ready
- [ ] Failure-Analysis bei < 8/10
- [ ] Bug Fixes basierend auf Logs

---

## ğŸš€ MVP Success Criteria

**Definition of Done:**
```
Task: "Finde eine Winter-Jacke fÃ¼r Damen"
URL: https://www.otto.de

Success = 8 von 10 Tests erreichen:
  âœ“ Cookie-Banner geklickt
  âœ“ Suchleiste gefunden
  âœ“ "Winter-Jacke" eingetippt (character-by-character)
  âœ“ Enter gedrÃ¼ckt ODER Search-Icon geklickt
  âœ“ Suchergebnisse geladen
  âœ“ Mindestens 1 Produkt angeklickt
  âœ“ Produktdetail-Seite erreicht
  âœ“ "finish" mit Rationale: "Ich sehe Preis + Warenkorb"
```

---

## ğŸ“¦ Modul-Ãœbersicht (Wie sie zusammenspielen)

### Modul 1: GOTT (Persona Factory)
```typescript
// Input
task: "Finde Winter-Jacke fÃ¼r junge Frauen"
domain: "ecommerce"
personaType: "pragmatic"

// Output
persona: {
  demographics: "Lisa, 24, Studentin",
  motivation: "Sucht warme Jacke fÃ¼r Uni-Weg",
  behavior: "Nutzt Suche, filtert nach Preis",
  constraints: "Budget: 50-100â‚¬"
}
```

**v1 (Basic)**: Live-Generierung aus Task  
**v2 (Premium)**: Analytics-Daten Integration

---

### Modul 2: RESEARCHER (Moderator & Auswertung)
```typescript
// Loop Detection
if (lastThreeActions.every(a => a.id === currentAction.id)) {
  intervention = "Du klickst 3x auf dasselbe. Scrolle oder probiere etwas anderes."
}

// IF MODERIERT: Fragen stellen
if (step % 2 === 0) {
  question = "Wie mÃ¼helos war dieser Schritt? (1-10)"
  pilotAnswer = await askLlava(question, screenshot)
}

// Finale Auswertung (PLUS)
if (allStepsComplete) {
  summary = await generateSummary(allLogs)
  // "8 von 10 Personas fanden die Suche mÃ¼helos..."
}
```

**v1 (Plus)**: Loop Detection + RAG (Baymard)  
**v2 (Premium)**: Analytics-Integration + A/B-Prediction

---

### Modul 3: PILOT (Execution)
```typescript
// Core Loop
while (step < maxSteps) {
  // 1. SEHEN
  screenshot = await page.screenshot()
  elements = await getInteractableElements()
  annotatedImage = await annotateWithBoundingBoxes(screenshot, elements)
  
  // 2. DENKEN
  visualIntent = await llava.analyze(annotatedImage, persona, task)
  logicalAction = await mistral.decide(visualIntent, elements, successCriteria)
  
  // 3. HANDELN (Human-like!)
  if (logicalAction.action === 'type') {
    await typeHumanLike(locator, logicalAction.text)
    if (logicalAction.submitWithEnter) {
      await locator.press('Enter')
    }
  }
  
  // 4. DOKUMENTIEREN
  log.push({
    step: step,
    intent: visualIntent,
    decision: logicalAction,
    screenshot: annotatedImage,
    timing: elapsed
  })
}
```

---

## ğŸ’¡ NÃ¤chste Features (Nach MVP)

### Phase 2: Moderierte Tests
- [ ] Researcher-Fragen einbauen
- [ ] "Warum hast du das geklickt?" nach jeder Action
- [ ] Qualitative Antworten von Llava
- [ ] PDF Report mit Quotes

### Phase 3: RAG Integration
- [ ] Baymard Knowledge Base
- [ ] NN Group Articles
- [ ] Context-aware Hints fÃ¼r Pilot
- [ ] "Pragmatic users prefer search" â†’ Pilot kriegt Hint

### Phase 4: Multi-Persona (n=10)
- [ ] Parallele AusfÃ¼hrung
- [ ] Aggregierte Auswertung
- [ ] Heatmap-Generierung
- [ ] Comparative Analysis

### Phase 5: Premium Features
- [ ] Adobe Analytics Integration
- [ ] Data-Driven Personas
- [ ] A/B-Test Vorhersagen
- [ ] Segment-Based Testing

---

## ğŸ“Š Metrics & KPIs

### MVP Success Metrics
- **Success Rate**: 8+/10 Tests erreichen Ziel
- **Avg. Steps**: < 10 Steps pro Test
- **Avg. Duration**: < 2 Min pro Test
- **Error Rate**: < 20% (ID not found, Timeout, etc.)

### Plus Package Metrics
- **Intervention Rate**: < 30% (Researcher muss eingreifen)
- **Loop Detection**: 100% (Keine Infinite Loops)
- **Report Quality**: Manuell bewertet (1-10)

### Premium Metrics
- **Prediction Accuracy**: A/B-Test Vorhersage vs. Real Results
- **Segment Coverage**: Mindestens 3 Segmente pro Test
- **Business Impact**: Conversion-Rate-Verbesserung messbar

---

## ğŸ”§ Technical Architecture

### Current (MVP Monolith)
```
app/api/run-simulation/route.ts
â”œâ”€ generatePersonaPrompt()    // Modul 1 (Lite)
â”œâ”€ getVisualIntention()        // Modul 3 (Llava)
â”œâ”€ getLogicalAction()          // Modul 3 (Mistral)
â”œâ”€ preFlightCookieClick()      // Helper
â””â”€ Main POST Handler           // Orchestration
```

### Future (Modular Services)
```
lib/
â”œâ”€ persona-factory/
â”‚  â”œâ”€ generatePersona.ts       // Modul 1
â”‚  â””â”€ analyzeTask.ts
â”œâ”€ researcher/
â”‚  â”œâ”€ detectLoops.ts           // Modul 2
â”‚  â”œâ”€ askQuestions.ts
â”‚  â””â”€ generateReport.ts
â”œâ”€ pilot/
â”‚  â”œâ”€ visualAgent.ts           // Modul 3
â”‚  â”œâ”€ humanLikeTyping.ts
â”‚  â””â”€ iconRecognition.ts
â””â”€ orchestrator/
   â”œâ”€ runSimulation.ts         // Main Entry
   â””â”€ streamProgress.ts        // SSE
```

---

## ğŸ“ Open Questions & Decisions Needed

### Q1: Typing Speed
- **Option A**: Fixed 50-150ms per character
- **Option B**: Persona-dependent (Pragmatic = faster, Inspirational = slower)
- **Decision**: ?

### Q2: Enter vs. Icon Click
- **Option A**: Always prefer Enter (faster)
- **Option B**: 50/50 Random (more realistic)
- **Decision**: ?

### Q3: Screenshot Frequency
- **Option A**: After EVERY action (storage heavy)
- **Option B**: Only on significant events (Search, Click Product)
- **Decision**: ?

### Q4: Success Criteria Definition
- **Option A**: User defines (Advanced Mode)
- **Option B**: Auto-detect (MVP: "Produkt-Detail-Seite erreicht")
- **Decision**: ?

---

## ğŸ“ Learnings & Best Practices

### Was funktioniert:
âœ… Bounding Box Approach (keine OCR!)  
âœ… Dual-LLM (Llava sieht, Mistral entscheidet)  
âœ… SSE fÃ¼r Live-Progress  
âœ… Visual Debug Logs (Screenshots)  

### Was nicht funktioniert:
âŒ Generic Personas ohne Task-Bezug  
âŒ Instant `fill()` (nicht menschlich)  
âŒ "finish" ohne klare Criteria  
âŒ Logs ohne Rationale  

### NÃ¤chste Experimente:
ğŸ§ª Icon-Recognition via Vision Model  
ğŸ§ª Autocomplete-Prediction  
ğŸ§ª Multi-Modal Input (Text + Voice)  
ğŸ§ª Real-Time Collaboration (Mehrere Researcher schauen zu)  

---

## ğŸ“š References

- **Vision**: `vision.md`
- **Pitch**: `pitch.md`
- **Backlog**: `backlog.md`
- **Current Route**: `app/api/run-simulation/route.ts`
- **Frontend**: `app/simulation/page.tsx`

---

**Last Updated**: 11. November 2025  
**Next Review**: Nach MVP Week 2